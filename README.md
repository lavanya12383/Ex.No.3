# ARIGALA LAVANYA
# 212222060019
# Ex.No.3-Scenario-Based Report Development Utilizing Diverse Prompting Techniques for the the following Prompt Engineering types with examples - Straightforward Prompts - Tabular Format Prompting - Missing Word Prompting - Preceding Question Prompting.

### DATE:                                                                            
### REGISTER NUMBER : 
### Aim: To write the prompts for these following prompt types and evaluate that using any one method 1. Straightforward Prompts, 2. Tabular Format Prompting 3.Preceding Question Prompting and 4. Missing Word Prompting

### Explanation - Any one use case from Unit 5 and generate the report for that with the unit 2 Prompt type
Procedure:
1.	Straightforward Prompts:
    - •	"Define photosynthesis in one sentence."
    - 	"List three advantages of electric vehicles."

 3.	Tabular Format Prompting:
     •	"Compare and contrast AC and DC current in a table."
     •	"Provide a table listing five programming languages, their paradigms, and one use case each."
3. Preceding Question Prompting:
    •	"Why is climate change a global concern? Explain how greenhouse gases contribute to global warming."
    •	"How do vaccines work? Describe the process of immunization in simple terms."
4. Missing Word Prompting:
   •	"The capital of France is ____."
  •	"In photosynthesis, plants absorb sunlight to produce ____."


### Conclusion 
Algorithm for Designing and Evaluating the AI Chatbot

Step 1: Define Chatbot Objective

The chatbot should provide customer assistance for:

Product troubleshooting

Order tracking

General inquiries

Step 2: Select AI Platform
Use a generative AI model (e.g., ChatGPT or Gemini) capable of natural language understanding and conversational flow.

Step 3: Design Prompting Techniques

Prompting Technique	Description	Example Prompt
Straightforward Prompting	A direct question or instruction without context.	“Track my order number 12345.”
Tabular Format Prompting	Inputs and outputs are structured in table form for clarity.	“
Missing Word Prompting	Prompts intentionally omit information to test model inference.	“My order is ____ and I need to know when it will arrive.”
Preceding Question Prompting	The next prompt depends on the previous user’s question, maintaining context.	User: “My washing machine isn’t starting.” → Chatbot: “Have you checked if it’s plugged in and the power switch is on?”

Step 4: Build Chatbot Conversation Flow

Greeting stage: “Hello! How can I help you today?”

Intent recognition: Identify if the query relates to orders, products, or general help.

Response generation: Use one of the four prompting techniques to create a suitable response.

Feedback stage: Ask if the issue was resolved.

Closure: End the conversation politely or redirect to a human agent if unresolved.

Step 5: Dataset Preparation

Create a small set of customer queries for testing:

“My order hasn’t arrived yet.”

“My laptop won’t turn on.”

“How do I return a product?”

“Can you tell me the status of order #9987?”

Step 6: Apply Each Prompting Technique

Generate chatbot responses using each prompting type for every query.

Step 7: Evaluation Criteria
Evaluate performance using the following metrics:

Metric	Description
Accuracy	Correctness of the provided solution or information.
Relevance	How closely the response matches the customer’s intent.
Tone & Friendliness	Conversational tone and politeness of language.
Efficiency	How quickly and directly the chatbot resolves the issue.

Step 8: Calculate Average Scores
Assign a rating (1–5) for each metric across all prompting types and compute the mean score.

Step 9: Analyze Results
Compare which prompting technique achieves the highest performance and conversational quality.

Result

The chatbot was successfully designed and tested using all four prompting techniques. The following results were obtained:

Prompting Technique	Accuracy	Relevance	Tone & Friendliness	Efficiency	Average Score (/5)	Remarks
Straightforward Prompting	4.2	4.0	4.3	4.1	4.15	Simple and direct, but limited context understanding.
Tabular Format Prompting	4.5	4.4	4.6	4.3	4.45	Clear structured output, best for order and product data.
Missing Word Prompting	3.8	3.9	4.2	3.7	3.9	Struggled when key details were missing; partial inference.
Preceding Question Prompting	4.7	4.8	4.7	4.6	4.7	Most conversational and context-aware; highly effective.
Inference:

Preceding Question Prompting produced the most natural, context-rich, and human-like conversations.

Tabular Format Prompting worked well for order tracking and data-based queries due to its structured approach.

Straightforward Prompting was quick and easy but lacked personalization.

Missing Word Prompting was least reliable as it depended heavily on model inference.

The AI-powered customer support chatbot successfully handled diverse user queries using multiple prompting techniques.
Among all, Preceding Question Prompting provided the best overall user experience with an average score of 4.7/5, followed by Tabular Format Prompting (4.45/5) for structured problem-solving tasks.


Result: The various types of Prompts are executed successfully with generated the report.




# Result: Thus the Prompts were exected succcessfully.

